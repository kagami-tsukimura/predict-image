import time

import matplotlib.pyplot as plt
import streamlit as st
import torch
from googletrans import Translator
from PIL import Image
from torchvision import models, transforms


def predict(img):
    """
    ä¸ãˆã‚‰ã‚ŒãŸç”»åƒã«å¯¾ã—ã¦äºˆæ¸¬ã‚’è¡Œã„ã€ç¢ºä¿¡åº¦ã®é«˜ã„ã‚¯ãƒ©ã‚¹ã¨ãã®ç¢ºä¿¡åº¦ã‚’è¿”ã™ã€‚

    Parameters:
        img (PIL.Image): äºˆæ¸¬å¯¾è±¡ã®ç”»åƒã€‚

    Returns:
        List[Tuple[str, float]]: ã‚¯ãƒ©ã‚¹åã¨ãã®ç¢ºä¿¡åº¦ã®ãƒªã‚¹ãƒˆã€‚
    """
    preprocessed_image = preprocess_image(img)
    img_tensor = torch.unsqueeze(preprocessed_image, 0)

    model = models.resnet101(pretrained=True)
    model.eval()
    output = model(img_tensor)

    output_prob = torch.nn.functional.softmax(torch.squeeze(output))
    sorted_prob, sorted_indices = torch.sort(output_prob, descending=True)
    CLASSES_FILE = "classes/imagenet_classes.txt"
    with open(CLASSES_FILE) as f:
        classes = [line.strip() for line in f.readlines()]
    return [
        (classes[idx], prob.item()) for idx, prob in zip(sorted_indices, sorted_prob)
    ]


def preprocess_image(img):
    """
    ç”»åƒã‚’å‰å‡¦ç†ã—ã¦ã€ãƒ¢ãƒ‡ãƒ«ã¸ã®å…¥åŠ›å½¢å¼ã«å¤‰æ›ã™ã‚‹ã€‚

    Parameters:
        image (PIL.Image): å‰å‡¦ç†å¯¾è±¡ã®ç”»åƒã€‚

    Returns:
        torch.Tensor: å‰å‡¦ç†ã•ã‚ŒãŸç”»åƒã®ãƒ†ãƒ³ã‚½ãƒ«ã€‚
    """
    transform = transforms.Compose(
        [
            transforms.Resize(256),
            transforms.CenterCrop(224),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
        ]
    )
    preprocessed_image = transform(img)
    return preprocessed_image


def main():
    """
    ç”»é¢è¡¨ç¤ºã™ã‚‹å‡¦ç†ã€‚
    """

    st.sidebar.title("ç”»åƒèªè­˜ã‚¢ãƒ—ãƒª")

    st.sidebar.write("**ResNet**ã‚’ä½¿ã£ã¦ä½•ã®ç”»åƒã‹ã‚’åˆ¤å®šã—ã¾ã™ã€‚")
    st.sidebar.write("")

    SOURCE_DICT = {"upload": "ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", "camera": "ã‚«ãƒ¡ãƒ©ã§æ’®å½±"}

    img_source = st.sidebar.radio("ç”»åƒã®ã‚½ãƒ¼ã‚¹ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚", tuple(SOURCE_DICT.values()))
    if img_source == SOURCE_DICT["upload"]:
        img_file = st.file_uploader("ç”»åƒã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚", type=["png", "jpg"])
    elif img_source == SOURCE_DICT["camera"]:
        img_file = st.camera_input("ã‚«ãƒ¡ãƒ©ã§æ’®å½±")

    if img_file:
        with st.spinner("åˆ¤å®šä¸­..."):
            img = Image.open(img_file)
            st.image(img, caption="å¯¾è±¡ã®ç”»åƒ", width=480)
            st.write("")

            results = predict(img)
            translator = Translator()
            predict_result_ja = translator.translate(
                results[0][0], src="en", dest="ja"
            ).text

            col1, col2 = st.columns(2)

            with col1:
                st.subheader(f"åˆ¤å®šçµæœ: {predict_result_ja}")
                # ä¸Šä½5ã‚¯ãƒ©ã‚¹ã¾ã§è¿”ã™
                N_TOP_5 = 5
                results_ja = []
                for i, result in enumerate(results[:N_TOP_5]):
                    results_ja.append(
                        translator.translate(result[0], src="en", dest="ja").text
                    )
                    st.markdown(
                        f"{i+1}. {str(round(result[1] * 100, 2))}%ã®ç¢ºç‡ã§{results_ja[i]}ã§ã™ã€‚"
                    )

            with col2:
                pie_labels = [result_ja for result_ja in results_ja[:N_TOP_5]]
                pie_labels.append("others")
                pie_probs = [result[1] for result in results[:N_TOP_5]]
                pie_probs.append(sum([result[1] for result in results[N_TOP_5:]]))
                result_dict = {k: v for k, v in zip(pie_labels, pie_probs)}
                # NOTE: 3%ä»¥ä¸Šã®ã¿ã‚°ãƒ©ãƒ•ã«è¡¨ç¤ºã—ã¦æ®‹ã‚Šã¯others
                filtered_result_dict = {
                    k: v for k, v in result_dict.items() if v >= 0.03
                }

                plt.rcParams["font.family"] = "Noto Sans CJK JP"
                fig, ax = plt.subplots()
                wedgeprops = {"width": 0.3, "edgecolor": "white"}
                textprops = {"fontsize": 12}
                ax.pie(
                    list(filtered_result_dict.values()),
                    labels=list(filtered_result_dict.keys()),
                    counterclock=False,
                    startangle=90,
                    textprops=textprops,
                    autopct="%.2f",
                    wedgeprops=wedgeprops,
                )
                st.pyplot(fig)
            st.toast("å®Œäº†ï¼", icon="ğŸ‰")
            time.sleep(1)
            st.toast("TIPS: ä»–ã®ç”»åƒã§ã‚‚æ˜¯éè©¦ã—ã¦ã¿ã¦ãã ã•ã„ã­ï¼", icon="ğŸ§")


if __name__ == "__main__":
    main()
